#!/usr/bin/env python3
"""
Google Search Console API 클라이언트

사용법:
    gsc sites                           # 등록된 사이트 목록
    gsc query <site_url>                # 검색 성능 데이터 조회
    gsc query <site_url> --days 30      # 최근 30일 데이터
    gsc query <site_url> --by-date      # 날짜별 조회

설정:
    1. Google Cloud Console에서 OAuth 2.0 클라이언트 ID 생성
    2. 클라이언트 시크릿 JSON 파일 다운로드
    3. 환경변수 설정: export GOOGLE_CLIENT_SECRET=~/.config/google/client_secret.json
    4. 첫 실행 시 브라우저에서 OAuth 인증 수행 (토큰 자동 저장)
"""

import argparse
import os
import pickle
import sys
from datetime import datetime, timedelta
from pathlib import Path

try:
    from google.auth.transport.requests import Request
    from google.oauth2.credentials import Credentials
    from google_auth_oauthlib.flow import InstalledAppFlow
    from googleapiclient.discovery import build
except ImportError:
    print("필수 패키지가 설치되어 있지 않습니다. 다음 명령어로 설치하세요:")
    print("  pip install google-auth google-auth-oauthlib google-api-python-client")
    sys.exit(1)

# API 스코프
SCOPES = ['https://www.googleapis.com/auth/webmasters.readonly']

# 인증 파일 경로
CLIENT_SECRET_FILE = os.environ.get(
    'GOOGLE_CLIENT_SECRET',
    os.path.expanduser('~/.config/google/client_secret.json')
)
TOKEN_FILE = os.path.expanduser('~/.config/gsc/token.pickle')


def get_credentials():
    """OAuth 2.0 인증을 수행하고 credentials를 반환합니다."""
    creds = None
    token_path = Path(TOKEN_FILE)

    # 클라이언트 시크릿 파일 확인
    if not os.path.exists(CLIENT_SECRET_FILE):
        print(f"오류: 클라이언트 시크릿 파일을 찾을 수 없습니다: {CLIENT_SECRET_FILE}")
        print()
        print("설정 방법:")
        print("  1. Google Cloud Console에서 OAuth 2.0 클라이언트 ID 생성")
        print("  2. 클라이언트 시크릿 JSON 파일 다운로드")
        print("  3. 파일을 ~/.config/google/client_secret.json에 저장")
        print("     또는 GOOGLE_CLIENT_SECRET 환경변수로 경로 지정")
        sys.exit(1)

    # 저장된 토큰이 있으면 로드
    if token_path.exists():
        with open(token_path, 'rb') as token:
            creds = pickle.load(token)

    # 토큰이 없거나 만료되었으면 새로 인증
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)
            creds = flow.run_local_server(port=0)

        # 토큰 저장
        token_path.parent.mkdir(parents=True, exist_ok=True)
        with open(token_path, 'wb') as token:
            pickle.dump(creds, token)

    return creds


def get_service():
    """Search Console API 서비스 객체를 반환합니다."""
    creds = get_credentials()
    return build('searchconsole', 'v1', credentials=creds)


def list_sites():
    """등록된 사이트 목록을 출력합니다."""
    service = get_service()
    response = service.sites().list().execute()

    sites = response.get('siteEntry', [])
    if not sites:
        print("등록된 사이트가 없습니다.")
        return

    print(f"\n{'=' * 60}")
    print("  등록된 사이트 목록")
    print(f"{'=' * 60}\n")

    for site in sites:
        url = site.get('siteUrl', '')
        permission = site.get('permissionLevel', '')
        print(f"  {url}")
        print(f"    권한: {permission}\n")


def query_search_analytics(site_url: str, days: int = 7, dimensions: list = None):
    """검색 성능 데이터를 조회합니다."""
    service = get_service()

    end_date = datetime.now() - timedelta(days=3)  # 최근 3일은 데이터 불완전
    start_date = end_date - timedelta(days=days)

    if dimensions is None:
        dimensions = ['query', 'page']

    request_body = {
        'startDate': start_date.strftime('%Y-%m-%d'),
        'endDate': end_date.strftime('%Y-%m-%d'),
        'dimensions': dimensions,
        'rowLimit': 100,
    }

    response = service.searchanalytics().query(
        siteUrl=site_url,
        body=request_body
    ).execute()

    rows = response.get('rows', [])

    print(f"\n{'=' * 80}")
    print(f"  검색 성능 데이터: {site_url}")
    print(f"  기간: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    print(f"{'=' * 80}\n")

    if not rows:
        print("  데이터가 없습니다.")
        return

    # 헤더
    print(f"{'클릭':>8} {'노출':>10} {'CTR':>8} {'순위':>8}  검색어 / 페이지")
    print("-" * 80)

    for row in rows[:50]:  # 상위 50개만 출력
        keys = row.get('keys', [])
        clicks = row.get('clicks', 0)
        impressions = row.get('impressions', 0)
        ctr = row.get('ctr', 0) * 100
        position = row.get('position', 0)

        query = keys[0] if len(keys) > 0 else ''
        page = keys[1] if len(keys) > 1 else ''

        print(f"{clicks:>8} {impressions:>10} {ctr:>7.1f}% {position:>8.1f}  {query[:30]}")
        if page:
            print(f"{' ' * 40}  {page[:60]}")

    print(f"\n총 {len(rows)}개 행")


def query_by_date(site_url: str, days: int = 30):
    """날짜별 검색 성능 데이터를 조회합니다."""
    service = get_service()

    end_date = datetime.now() - timedelta(days=3)
    start_date = end_date - timedelta(days=days)

    request_body = {
        'startDate': start_date.strftime('%Y-%m-%d'),
        'endDate': end_date.strftime('%Y-%m-%d'),
        'dimensions': ['date'],
        'rowLimit': 1000,
    }

    response = service.searchanalytics().query(
        siteUrl=site_url,
        body=request_body
    ).execute()

    rows = response.get('rows', [])

    print(f"\n{'=' * 60}")
    print(f"  날짜별 검색 성능: {site_url}")
    print(f"{'=' * 60}\n")

    print(f"{'날짜':<12} {'클릭':>8} {'노출':>10} {'CTR':>8} {'평균순위':>8}")
    print("-" * 60)

    for row in rows:
        date = row.get('keys', [''])[0]
        clicks = row.get('clicks', 0)
        impressions = row.get('impressions', 0)
        ctr = row.get('ctr', 0) * 100
        position = row.get('position', 0)

        print(f"{date:<12} {clicks:>8} {impressions:>10} {ctr:>7.1f}% {position:>8.1f}")


def main():
    parser = argparse.ArgumentParser(description='Google Search Console CLI')
    subparsers = parser.add_subparsers(dest='command', help='명령어')

    # sites 명령어
    subparsers.add_parser('sites', help='등록된 사이트 목록')

    # query 명령어
    query_parser = subparsers.add_parser('query', help='검색 성능 데이터 조회')
    query_parser.add_argument('site_url', help='사이트 URL (예: https://example.com/)')
    query_parser.add_argument('--days', type=int, default=7, help='조회 기간 (일)')
    query_parser.add_argument('--by-date', action='store_true', help='날짜별 조회')

    args = parser.parse_args()

    if args.command == 'sites':
        list_sites()
    elif args.command == 'query':
        if args.by_date:
            query_by_date(args.site_url, args.days)
        else:
            query_search_analytics(args.site_url, args.days)
    else:
        parser.print_help()


if __name__ == '__main__':
    main()
